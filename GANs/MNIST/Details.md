GANs are a framework for teaching a DL model to capture the training data’s distribution so we can generate new data from that same distribution. GAN's are typically **generative models** . Generative models learn the intrinsic distribution function of the input data **p(x)** allowing them to generate both synthetic inputs **x'** and outputs/targets **y'**, typically given some hidden parameters.

Generative Adversarial Networks are composed of two models:

*   **Generator** : It aims to generate new data similar to the expected one.
*   **Discriminator**: This model’s goal is to recognize if an input data is ‘real’ — belongs to the original dataset — or if it is ‘fake’ — generated by a **Generator**

The output results are as follows:

# TRAINED ON MNIST DATA SET

**GAN's** run using a fully connected Deep Neural Network with 3 Hidden layers and 1 output layer in each of the

**Generator**([100,256],[256,512],[512,1024],[1024,784]) and

**Discriminator**([784,1024],[1024,512],[512,256],[256,1]).

**Loss Function** as **Binary Cross Entopy**

**Optimizer**= Adam

**Learning rate**= 0.0002

**Number of epochs** = 200
